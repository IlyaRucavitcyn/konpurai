<div>
  <h3>Bias & Fairness Assessment</h3>
  <p>
    The Bias & Fairness Assessment system provides comprehensive tools to
    monitor and evaluate AI model fairness metrics, identify potential biases,
    and ensure your AI systems operate equitably across different demographic
    groups. This system supports classification models and provides detailed
    analysis of fairness across various metrics to help you build more
    responsible AI systems.
  </p>

  <section>
    <h3>Overview</h3>
    <p>The Bias & Fairness Dashboard consists of two main components:</p>
    <ul>
      <li>
        <strong>Fairness Checks:</strong> Upload and manage AI models for bias
        assessment
      </li>
      <li>
        <strong>Detailed Results:</strong> View comprehensive fairness metrics
        and analysis
      </li>
    </ul>
  </section>

  <section>
    <h3>System Requirements</h3>
    <p>
      Before using the bias and fairness assessment system, ensure your setup
      meets these requirements:
    </p>
    <ul>
      <li>
        <strong>Model Type:</strong> Only classification models are currently
        supported
      </li>
      <li>
        <strong>Model Format:</strong> Models must be in .pkl (pickle) format
      </li>
      <li>
        <strong>Preprocessing:</strong> Models should include preprocessing
        steps (e.g., sklearn.Pipeline)
      </li>
      <li><strong>Dataset Format:</strong> Datasets must be in .csv format</li>
      <li>
        <strong>Data Compatibility:</strong> Dataset must be formatted to match
        the model's input requirements
      </li>
      <li><strong>File Size:</strong> Maximum file size is 200MB per file</li>
    </ul>
  </section>

  <section>
    <h3>Uploading Models for Assessment</h3>
    <p>To start a new fairness assessment, follow these steps:</p>
    <ol>
      <li>
        <strong>Click "Validate fairness":</strong> This opens the upload dialog
      </li>
      <li>
        <strong>Upload Model File:</strong> Select your .pkl model file
        <ul>
          <li>Click "Choose model file" button</li>
          <li>Select your .pkl file from your computer</li>
          <li>The file will be compressed and uploaded securely</li>
        </ul>
      </li>
      <li>
        <strong>Upload Dataset File:</strong> Select your .csv dataset file
        <ul>
          <li>Click "Choose dataset file" button</li>
          <li>Select your .csv file from your computer</li>
          <li>The system will automatically read column headers</li>
        </ul>
      </li>
      <li>
        <strong>Select Target Column:</strong> Choose the column that represents
        your prediction target
        <ul>
          <li>
            Available columns are automatically populated from your dataset
          </li>
          <li>This is the variable your model is trying to predict</li>
        </ul>
      </li>
      <li>
        <strong>Select Sensitive Column:</strong> Choose the column representing
        the sensitive attribute
        <ul>
          <li>
            This is the demographic or protected attribute you want to test for
            bias
          </li>
          <li>Examples: gender, race, age group, etc.</li>
        </ul>
      </li>
      <li>
        <strong>Click "Upload":</strong> The system will process your files and
        start the assessment
      </li>
    </ol>
  </section>

  <section>
    <h3>Assessment Process</h3>
    <p>
      Once you upload your model and dataset, the system follows this process:
    </p>
    <ol>
      <li>
        <strong>File Processing:</strong> Your files are compressed and uploaded
        securely
      </li>
      <li>
        <strong>Model Validation:</strong> The system validates your model
        format and compatibility
      </li>
      <li>
        <strong>Data Analysis:</strong> The dataset is analyzed to extract
        column information
      </li>
      <li>
        <strong>Fairness Calculation:</strong> Multiple fairness metrics are
        calculated across different groups
      </li>
      <li>
        <strong>Results Generation:</strong> Comprehensive fairness reports are
        generated
      </li>
      <li>
        <strong>Status Updates:</strong> You can monitor the progress in the
        fairness checks table
      </li>
    </ol>
  </section>

  <section>
    <h3>Fairness Checks Table</h3>
    <p>
      The main table displays all your fairness assessments with the following
      information:
    </p>
    <ul>
      <li>
        <strong>Check ID:</strong> Unique identifier for each fairness
        assessment
      </li>
      <li><strong>Model:</strong> Name of the uploaded model file</li>
      <li><strong>Dataset:</strong> Name of the uploaded dataset file</li>
      <li>
        <strong>Status:</strong> Current status of the assessment
        <ul>
          <li><strong>In Progress:</strong> Assessment is currently running</li>
          <li><strong>Completed:</strong> Assessment finished successfully</li>
          <li><strong>Failed:</strong> Assessment encountered an error</li>
        </ul>
      </li>
      <li>
        <strong>Report:</strong> Access to detailed fairness results (when
        completed)
      </li>
      <li><strong>Action:</strong> Available actions for each assessment</li>
    </ul>
  </section>

  <section>
    <h3>Status Indicators</h3>
    <p>Each fairness check displays a status badge with color coding:</p>
    <ul>
      <li>
        <strong>In Progress (Yellow):</strong> Assessment is currently running
        <ul>
          <li>Shows "Pending..." in the Check ID column</li>
          <li>Report and delete actions are disabled</li>
        </ul>
      </li>
      <li>
        <strong>Completed (Green):</strong> Assessment finished successfully
        <ul>
          <li>Shows the actual Check ID</li>
          <li>All actions are available</li>
        </ul>
      </li>
      <li>
        <strong>Failed (Red):</strong> Assessment encountered an error
        <ul>
          <li>Failed assessments are automatically removed after 60 seconds</li>
          <li>Check your model and dataset compatibility</li>
        </ul>
      </li>
    </ul>
  </section>

  <section>
    <h3>Viewing Fairness Results</h3>
    <p>To view detailed fairness metrics for a completed assessment:</p>
    <ol>
      <li>
        <strong>Find Completed Assessment:</strong> Look for assessments with
        "Completed" status
      </li>
      <li>
        <strong>Click "Show" Button:</strong> This opens the detailed fairness
        results page
      </li>
      <li>
        <strong>Review Metrics:</strong> The results page displays comprehensive
        fairness analysis
      </li>
    </ol>
  </section>

  <section>
    <h3>Fairness Metrics Explained</h3>
    <p>The system calculates several key fairness metrics:</p>

    <h4>Overall Fairness Metrics:</h4>
    <ul>
      <li>
        <strong>Accuracy:</strong> Overall correctness of the model's
        predictions
      </li>
      <li>
        <strong>Demographic Parity Difference:</strong> Measures how equally
        outcomes are distributed across groups. Lower values indicate fairer
        outcomes.
      </li>
      <li>
        <strong>Equal Opportunity Difference:</strong> Measures gaps in true
        positive rate (TPR) between groups. Lower values mean more equal
        opportunity.
      </li>
      <li>
        <strong>Equalized Odds Difference:</strong> Difference in true positive
        and false positive rates between groups. Lower values indicate less
        bias.
      </li>
    </ul>

    <h4>Disparity Metrics:</h4>
    <ul>
      <li>
        <strong>Selection Rate Difference:</strong> Shows the difference in
        selection rates between groups
      </li>
      <li>
        <strong>True Positive Rate (TPR) Difference:</strong> Shows the
        difference in TPR between groups
      </li>
      <li>
        <strong>True Negative Rate (TNR) Difference:</strong> Shows the
        difference in TNR between groups
      </li>
    </ul>

    <h4>Group-wise Analysis:</h4>
    <ul>
      <li>
        <strong>Accuracy by Group:</strong> Shows accuracy for each demographic
        group
      </li>
      <li>
        <strong>Selection Rate by Group:</strong> Shows selection rates for each
        group
      </li>
      <li>
        <strong>TPR by Group:</strong> Shows true positive rates for each group
      </li>
      <li>
        <strong>TNR by Group:</strong> Shows true negative rates for each group
      </li>
    </ul>
  </section>

  <section>
    <h3>Interpreting Results</h3>
    <p>Understanding your fairness assessment results:</p>
    <ul>
      <li>
        <strong>Lower Difference Values:</strong> Generally indicate fairer
        outcomes across groups
      </li>
      <li>
        <strong>Group-wise Charts:</strong> Visualize performance differences
        between demographic groups
      </li>
      <li>
        <strong>Tooltips:</strong> Hover over info icons for detailed
        explanations of each metric
      </li>
      <li>
        <strong>Color Coding:</strong> Charts use consistent colors to represent
        different groups
      </li>
    </ul>
  </section>

  <section>
    <h3>Managing Assessments</h3>
    <p>For each fairness check in the table, you can:</p>
    <ul>
      <li>
        <strong>View Results:</strong> Click "Show" to view detailed fairness
        metrics (only for completed assessments)
      </li>
      <li>
        <strong>Delete Assessment:</strong> Click the trash icon to remove an
        assessment
        <ul>
          <li>Only available for completed assessments</li>
          <li>Requires confirmation before deletion</li>
          <li>This action is non-recoverable</li>
        </ul>
      </li>
    </ul>
  </section>

  <section>
    <h3>Pagination and Navigation</h3>
    <p>The fairness checks table includes pagination controls:</p>
    <ul>
      <li>
        <strong>Rows Per Page:</strong> Choose how many assessments to display
        (5, 10, 15, or 20)
      </li>
      <li>
        <strong>Page Navigation:</strong> Navigate between pages using
        pagination controls
      </li>
      <li>
        <strong>Item Count:</strong> View the total number of assessments and
        current page range
      </li>
    </ul>
  </section>

  <section>
    <h3>Empty State</h3>
    <p>
      When no fairness assessments have been performed, the system displays:
    </p>
    <ul>
      <li><strong>Visual Indicator:</strong> An empty state illustration</li>
      <li>
        <strong>Informative Message:</strong> "There is currently no data in
        this table."
      </li>
      <li>
        <strong>Guidance:</strong> Use the "Validate fairness" button to start
        your first assessment
      </li>
    </ul>
  </section>

  <section>
    <h3>Best Practices</h3>
    <ul>
      <li>
        <strong>Model Preparation:</strong> Ensure your model includes all
        necessary preprocessing steps
      </li>
      <li>
        <strong>Data Quality:</strong> Use clean, well-formatted datasets with
        clear column headers
      </li>
      <li>
        <strong>Sensitive Attributes:</strong> Choose meaningful sensitive
        attributes that represent protected characteristics
      </li>
      <li>
        <strong>Target Selection:</strong> Ensure your target column represents
        the actual prediction goal
      </li>
      <li>
        <strong>Regular Assessment:</strong> Perform fairness assessments
        regularly as you update your models
      </li>
      <li>
        <strong>Documentation:</strong> Keep records of your fairness
        assessments for compliance purposes
      </li>
    </ul>
  </section>

  <section>
    <h3>Technical Details</h3>
    <p>The system uses advanced techniques for fairness assessment:</p>
    <ul>
      <li>
        <strong>File Compression:</strong> Files are compressed using gzip
        before upload for efficiency
      </li>
      <li>
        <strong>Asynchronous Processing:</strong> Assessments run in the
        background with status updates
      </li>
      <li>
        <strong>Exponential Backoff:</strong> Status checking uses exponential
        backoff for efficient polling
      </li>
      <li>
        <strong>Secure Upload:</strong> Files are uploaded securely with proper
        authentication
      </li>
    </ul>
  </section>

  <section>
    <h3>Troubleshooting</h3>
    <p>Common issues and solutions:</p>
    <ul>
      <li>
        <strong>Upload Fails:</strong> Check file format (.pkl for models, .csv
        for datasets) and file size (max 200MB)
      </li>
      <li>
        <strong>Assessment Fails:</strong> Ensure your model includes
        preprocessing and dataset matches model requirements
      </li>
      <li>
        <strong>Column Not Found:</strong> Verify your dataset has the columns
        you're trying to select
      </li>
      <li>
        <strong>Long Processing Time:</strong> Large datasets may take several
        minutes to process
      </li>
      <li>
        <strong>Status Not Updating:</strong> Refresh the page if status updates
        seem stuck
      </li>
    </ul>
  </section>

  <section>
    <h3>Security and Privacy</h3>
    <p>The bias and fairness assessment system prioritizes security:</p>
    <ul>
      <li>
        <strong>Secure Upload:</strong> All files are uploaded over encrypted
        connections
      </li>
      <li>
        <strong>Data Processing:</strong> Files are processed securely and not
        stored longer than necessary
      </li>
      <li>
        <strong>Access Control:</strong> Only authorized users can access
        fairness assessment features
      </li>
      <li>
        <strong>Audit Trail:</strong> All assessment activities are logged for
        compliance
      </li>
    </ul>
  </section>
</div>
